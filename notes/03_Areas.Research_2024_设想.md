---
id: 3ux3mg2wa77lg4lwkcyl9ku
title: Research_2024_设想
desc: ''
updated: 1706851285607
created: 1706713780613
---


这个文档是用来记录2024年的研究idea，主要是记录一些零散的想法，然后实时更新，不断优化。


## 连环画生成




## 多物体定制化+准确Interactions生成




## 给定参考图的Interactions生成或编辑



## 多物体交互的定制化生成

* 人和单物体的交互定制化
* 人和场景的交互定制化
* 多物体的交互定制化

* GenZI: Zero-Shot 3D Human-Scene Interaction Generatio



## 物体形象定制+Action定制化
总体来说，我们希望同时定制人物或者物体的concept，同时定制一个action。然后生成一个完整的场景，让人物在这个场景中表演这个action。

现有的方法基本都是要么定制概念，然后用文本驱动这个概念执行某种action，要么就是定制action或者relation。我们的方法目的是给定一张人物形象照片，在给定一个action照片，分别定制，然后得到执行这个action的人的图像。

甚至可以更进一步，给定一个场景照片，让人物在这个场景中表演这个action。

这可能需要举一些非常吸引人的例子，例如上传一个演员的照片和一个动作概念（比如“跳伞”），然后系统生成一个逼真的跳伞场景，其中包含了执行该动作的定制化人物形象。

为什么要有这个想法？或者说怎么验证这个想法能够立得住？

* 现在没有这样的工作
* 当前的这些人物形象定制化的方法，不能完成精准的action生成
  * 简单动作
  * 复杂动作
* 现在这些action和relation定制的方法，无法实现特定任务形象的定制

但是现在有个问题，Animate相关的工作，其实已经实现了这个功能。

## 主谓宾定制

主语和宾语都是物体概念，比如狗和咖啡；谓语则是关系或者动词，比如喝。

给定一张主语和宾语的图像，同时在给定一张关系图像，系统可以生成一个完整的场景，其中包含了主语和宾语的定制化图像，以及关系的定制化图像。

比如狗+苹果+eat，或者狗+镜子+照。

这个想法如果成立，则需要满足以下条件：

* 多概念定制对于概念间的interaction生成的不好


根据我的观察，我发现多概念定制化的结果，概念之间基本没有interaction。都是简单的布局摆在那里。




