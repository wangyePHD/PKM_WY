---
id: sjx3idkx59omo1oqhvw0vz6
title: 参考文献
desc: ''
updated: 1702882030670
created: 1702797711288
---


* ediffi: Text-to-image diffusion models with an ensemble of expert denoisers.
* Muse: Text-to-image generation via masked generative transformers
* Cogview: Mastering text-to-image generation via transformers
* Cogview2: Faster and better text-to-image generation via hierarchical transformers
* Make-a-scene: Scenebased text-to-image generation with human priors
* Controllable text-to-image generation
* Glide: Towards photorealistic image generation and editing with text-guided diffusion models
* Hierarchical text-conditional image generation with clip latents
* Zero-shot text-to-image generation
* High-resolution image synthesis with latent diffusion models
* Photorealistic text-to-image diffusion models with deep language understanding
* Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis
* Tedigan: Text-guided diverse face image generation and manipulation.
* Scaling autoregressive models for content-rich text-to-image generation.





定制化图像生成：

* Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation
* Multi-concept customization of text-to-image diffusion
* Svdiff: Compact parameter space for diffusion fine-tuning
* 我是分割线
* Designing an encoder for fast personalization of text-to-image models
* Elite: Encoding visual concepts into textual embeddings for customized textto-image generation.
* Hyperdreambooth: Hypernetworks for fast personalization of text-to-image models
* Subject-driven text-to-image generation via apprenticeship learning
* Instantbooth: Personalized text-to-image generation without test-time finetuning
* Taming encoder for zero fine-tuning image customization with text-to-image diffusion models
* Break-a-scene: Extracting multiple concepts from a single image
* Fastcomposer: Tuning-free multi-subject image generation with localized attention