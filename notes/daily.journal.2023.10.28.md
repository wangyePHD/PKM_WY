---
id: vv23u325k5tmfq2iy57pc3h
title: '2023.10.28'
desc: ''
updated: 1698472561296
created: 1698457898556
---



### <font color=red>**重要紧急**</font>
- [x]  每日Arxiv
- [ ]  每日论文阅读
  - [x]  HYPERFIELDS: TOWARDS ZERO-SHOT GENERATION OF NERFS FROM TEXT
  - [x]  Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model
  - [x]  ATT3D: Amortized Text-to-3D Object Synthesis
    - [x]  上述3篇论文泛读完毕
  - [x] INTEGRATING VIEW CONDITIONS FOR IMAGE SYNTHESIS 阅读完毕，笔记已整理
  - [x] Reference-based Image Composition with Sketch via Structure-aware Diffusion Model, 阅读完毕，笔记已整理
- [ ] 总结现阶段的问题
- [ ] 整理Textual Inversion论文，文献树，笔记库
- [ ]  思考新实验的验证思路和下一步的计划


### <font color=#871F78>**不重要紧急**</font>

- [ ] 无



### <font color=blue>**重要不紧急**</font>

- [ ] FlowUs长期事项


### <font color=green>**不重要不紧急**</font>
- [x]  Daily Notes模板更新一下
- [ ]  markdown base64图像存储
- [ ]  FlowUs剪藏内容尝试一下

## **工作笔记**

* **2023年10月28日10:53:07**：关注到了Text-NeRF-Mapping的三篇论文，这三篇论文都是目前最新的文章，一篇ICCV23，两篇ICLR24在投。分别是：
  *  HYPERFIELDS: TOWARDS ZERO-SHOT GENERATION OF NERFS FROM TEXT
  *  Instant3D: Fast Text-to-3D with Sparse-view Generation and Large Reconstruction Model
  *  ATT3D: Amortized Text-to-3D Object Synthesis
  *  上述文章结合我和yibo最近思考的In-Context Learning想法，感觉有很多可做的事情。今天可以稍微总结一下。
*  **2023年10月28日13:25:53**: INTEGRATING VIEW CONDITIONS FOR IMAGE SYNTHESIS，又是一篇多模型组合的文章。可以认为是在Paint-by-Example的基础上，在一致性、和谐、视角可控的进一步提升。我看实验中，还比较了一个工作：


## **问题记录**

1.
2.
3.


## **今日总结**

1.
2.
3.
